{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796f8440-36cd-45bd-9499-eb5b6ea0dd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Turn light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3039456c-a97d-4f8c-8b03-31d873e43355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "trainDir=\"/home/madmax/Documents/SK_articles/test_povorotniks/cutted_DATASET/largus/\"\n",
    "\n",
    "imgs=[]\n",
    "for pth in os.listdir(trainDir):\n",
    "    imgs.append(trainDir+\"/\"+pth )\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95818aaa-d36b-4bd9-8394-91bd8137fc95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import cv2\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import os\n",
    "batchSize=1\n",
    "imageSize=[200,200]\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd14c6b-2340-47da-b875-9c549a5b1926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def saver_predict_with_classes (img_path, network, path_out, score): \n",
    "#      images = cv2.imread(img_path)\n",
    "#      images = cv2.resize(images, imageSize, cv2.INTER_LINEAR)def saver_predict_with_classes (img_path, network, path_out, score): \n",
    "#      images = cv2.imread(img_path)\n",
    "#      images = cv2.resize(images, imageSize, cv2.INTER_LINEAR)\n",
    "#      images = torch.as_tensor(images, dtype=torch.float32).unsqueeze(0)\n",
    "#      images=images.swapaxes(1, 3).swapaxes(2, 3)def saver_predict_with_classes (img_path, network, path_out, score): \n",
    "#      images = cv2.imread(img_path)\n",
    "#imageSize=[200,200]\n",
    "#      images = cv2.resize(images, imageSize, cv2.INTER_LINEAR)\n",
    "#      images = torch.as_tensor(images, dtype=torch.float32).unsqueeze(0)\n",
    "#      images=images.swapaxes(1, 3).swapaxes(2, 3)\n",
    "#      images = list(image.to(device) for image in images)\n",
    "#      im= images[0].swapaxes(0, 2).swapaxes(0, 1).detach().cpu().numpy().astype(np.uint8)\n",
    "#      im2 = im.copy()\n",
    "#      class_color_list = [[0,0,0],[0,0,128],[0,0,255], [255, 0,0], [255,0,128]]\n",
    "#      with torch.no_grad():\n",
    "#        pred = network(images)\n",
    "#      print(pred[0]['labels'])\n",
    "#      for i in range(len(pred[0]['masks'])):\n",
    "#         msk=pred[0]['masks'][i,0].detach().cpu().numpy()\n",
    "#         scr=pred[0]['scores'][i].detach().cpu().numpy()\n",
    "#         label = pred[0]['labels'][i].detach().cpu().numpy()\n",
    "#         if scr>score:\n",
    "#             im2[:,:,0][msk>0.5], im2[:,:,1][msk>0.5], im2[:,:,2][msk>0.5] = class_color_list[label]        \n",
    "#             print(path_out+img_path.split('/')[-1])\n",
    "#             a = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "#             cv2.imwrite(path_out+img_path.split('/')[-1], np.hstack([im,im2]))\n",
    "#             #cv2.imwrite(path_out+img_path.split('/')[-1],a)\n",
    "            \n",
    "#      images = list(image.to(device) for image in images)\n",
    "#      im= images[0].swapaxes(0, 2).swapaxes(0, 1).detach().cpu().numpy().astype(np.uint8)\n",
    "#      im2 = im.copy()\n",
    "#      class_color_list = [[0,0,0],[0,0,128],[0,0,255], [255, 0,0], [255,0,128]]\n",
    "#      with torch.no_grad():def saver_predict_with_classes (img_path, network, path_out, score): \n",
    "#      images = cv2.imread(img_path)\n",
    "#      images = cv2.resize(images, imageSize, cv2.INTER_LINEAR)\n",
    "#      images = torch.as_tensor(images, dtype=torch.float32).unsqueeze(0)\n",
    "#      images=images.swapaxes(1, 3).swapaxes(2, 3)\n",
    "#      images = list(image.to(device) for image in images)\n",
    "#      im= images[0].swapaxes(0, 2).swapaxes(0, 1).detach().cpu().numpy().astype(np.uint8)\n",
    "#      im2 = im.copy()\n",
    "#      class_color_list = [[0,0,0],[0,0,128],[0,0,255], [255, 0,0], [255,0,128]]\n",
    "#      with torch.no_grad():\n",
    "#        pred = network(images)\n",
    "#      print(pred[0]['labels'])\n",
    "#      for i in range(len(pred[0]['masks'])):\n",
    "#         msk=pred[0]['masks'][i,0].detach().cpu().numpy()Привет\n",
    "#         scr=pred[0]['scores'][i].detach().cpu().numpy()\n",
    "#         label = pred[0]['labels'][i].detach().cpu().numpy()\n",
    "#         if scr>score:\n",
    "#             im2[:,:,0][msk>0.5], im2[:,:,1][msk>0.5], im2[:,:,2][msk>0.5] = class_color_list[label]        \n",
    "#             print(path_out+img_path.split('/')[-1])\n",
    "#             a = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "#             cv2.imwrite(path_out+img_path.split('/')[-1], np.hstack([im,im2]))\n",
    "#             #cv2.imwrite(path_out+img_path.split('/')[-1],a)\n",
    "            \n",
    "#        pred = network(images)\n",
    "#      print(pred[0]['labels'])\n",
    "#      for i in range(len(pred[0]['masks'])):\n",
    "#         msk=pred[0]['masks'][i,0].detach().cpu().numpy()\n",
    "#         scr=pred[0]['scores'][i].detach().cpu().numpy()\n",
    "#         label = pred[0]['labels'][i].detach().cpu().numpy()\n",
    "#         if scr>score:\n",
    "#             im2[:,:,0][msk>0.5], im2[:,:,1][msk>0.5], im2[:,:,2][msk>0.5] = class_color_list[label]        \n",
    "#             print(path_out+img_path.split('/')[-1])\n",
    "#             a = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "#             cv2.imwrite(path_out+img_path.split('/')[-1], np.hstack([im,im2]))\n",
    "#             #cv2.imwrite(path_out+img_path.split('/')[-1],a)\n",
    "            \n",
    "#      images = torch.as_tensor(images, dtype=torch.float32).unsqueeze(0)\n",
    "#      images=images.swapaxes(1, 3).swapaxes(2, 3)\n",
    "#      images = list(image.to(device) for image in images)\n",
    "#      im= images[0].swapaxes(0, 2).swapaxes(0, 1).detach().cpu().numpy().astype(np.uint8)\n",
    "#      im2 = im.copy()\n",
    "#      class_color_list = [[0,0,0],[0,0,128],[0,0,255], [255, 0,0], [255,0,128]]\n",
    "#      with torch.no_grad():\n",
    "#        pred = network(images)\n",
    "#      print(pred[0]['labels'])\n",
    "#      for i in range(len(pred[0]['masks'])):\n",
    "#         msk=pred[0]['masks'][i,0].detach().cpu().numpy()\n",
    "#         scr=pred[0]['scores'][i].detach().cpu().numpy()\n",
    "#         label = pred[0]['labels'][i].detach().cpu().numpy()\n",
    "#         if scr>score:\n",
    "#             im2[:,:,0][msk>0.5], im2[:,:,1][msk>0.5], im2[:,:,2][msk>0.5] = class_color_list[label]        \n",
    "#             print(path_out+img_path.split('/')[-1])\n",
    "#             a = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "#             cv2.imwrite(path_out+img_path.split('/')[-1], np.hstack([im,im2]))\n",
    "#             #cv2.imwrite(path_out+img_path.split('/')[-1],a)\n",
    "            \n",
    "            \n",
    "            \n",
    "def saver_predict_with_classes (img_path, network, path_out, score): \n",
    "     images = cv2.imread(img_path)\n",
    "     images = cv2.resize(images, imageSize, cv2.INTER_LINEAR)\n",
    "     images = torch.as_tensor(images, dtype=torch.float32).unsqueeze(0)\n",
    "     images=images.swapaxes(1, 3).swapaxes(2, 3)\n",
    "     images = list(image.to(device) for image in images)\n",
    "     im= images[0].swapaxes(0, 2).swapaxes(0, 1).detach().cpu().numpy().astype(np.uint8)\n",
    "     im2 = im.copy()\n",
    "     class_color_list = [[0,0,0],[0,0,128],[0,0,255], [255, 0,0], [255,0,128]]\n",
    "     with torch.no_grad():\n",
    "       pred = network(images)\n",
    " #fll 1\n",
    "     print(pred[0]['labels'])\n",
    "     for i in range(len(pred[0]['masks'])):\n",
    "        msk=pred[0]['masks'][i,0].detach().cpu().numpy()\n",
    "        scr=pred[0]['scores'][i].detach().cpu().numpy()\n",
    "        label = pred[0]['labels'][i].detach().cpu().numpy()\n",
    "        if scr>score:\n",
    "            im2[:,:,0][msk>0.5], im2[:,:,1][msk>0.5], im2[:,:,2][msk>0.5] = class_color_list[label]        \n",
    "            print(path_out+img_path.split('/')[-1])\n",
    "     cv2.imwrite(path_out+img_path.split('/')[-1], np.hstack([im,im2]))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f000eec9-cb08-4d33-88bc-73e47a910903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madmax/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/madmax/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "device = torch.device('cpu') if torch.cuda.is_available() else torch.device('cpu')  \n",
    "model=torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True) \n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features \n",
    "model.roi_heads.box_predictor=FastRCNNPredictor(in_features,num_classes=5)\n",
    "model.load_state_dict(torch.load(\"7000.torch\"))\n",
    "model.to(device)# move model to the right devic\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862e1eb1-6b78-4a38-853c-a9b5a3b4abfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/madmax/Documents/SK_articles/test_povorotniks/cutted_DATASET/largus//11370_image2245.png', '/home/madmax/Documents/SK_articles/test_povorotniks/cutted_DATASET/largus//11375_image3021.png', '/home/madmax/Documents/SK_articles/test_povorotniks/cutted_DATASET/largus//11380_image52.png', '/home/madmax/Documents/SK_articles/test_povorotniks/cutted_DATASET/largus//11385_image168.png', '/home/madmax/Documents/SK_articles/test_povorotniks/cutted_DATASET/largus//11390_image1118.png']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'saver_predict_with_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tester:\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m pth \u001b[38;5;129;01min\u001b[39;00m imgs:   \n\u001b[0;32m----> 7\u001b[0m     \u001b[43msaver_predict_with_classes\u001b[49m (pth, model,output_path, \u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'saver_predict_with_classes' is not defined"
     ]
    }
   ],
   "source": [
    "output_path = \"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/\"\n",
    "imgs.sort()\n",
    "print(imgs)\n",
    "tester = True\n",
    "if tester:\n",
    "  for pth in imgs:   \n",
    "    saver_predict_with_classes (pth, model,output_path, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ec7c564-adac-44ad-b781-0d6558ecc711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def turn_saver (img_path, network, path_out, score, turn_label): \n",
    "     counter = 0\n",
    "     images = cv2.imread(img_path)\n",
    "     images = cv2.resize(images, imageSize, cv2.INTER_LINEAR)\n",
    "     images = torch.as_tensor(images, dtype=torch.float32).unsqueeze(0)\n",
    "     images=images.swapaxes(1, 3).swapaxes(2, 3)\n",
    "     images = list(image.to(device) for image in images)\n",
    "     im= images[0].swapaxes(0, 2).swapaxes(0, 1).detach().cpu().numpy().astype(np.uint8)\n",
    "     \n",
    "     class_color_list = [[0,0,0],[0,0,128],[0,0,255], [255, 0,0], [255,0,128]]\n",
    "     with torch.no_grad():\n",
    "       pred = network(images)\n",
    "     #print(pred[0]['labels'])\n",
    "     for i in range(len(pred[0]['masks'])):\n",
    "        msk=pred[0]['masks'][i,0].detach().cpu().numpy()\n",
    "        scr=pred[0]['scores'][i].detach().cpu().numpy()\n",
    "        label = pred[0]['labels'][i].detach().cpu().numpy()\n",
    "        #print(pred[0]['boxes'][i])\n",
    "        im2 = im.copy()\n",
    "        if label == turn_label:\n",
    "          if scr>score:\n",
    "            im2[:,:,0][msk<0.5], im2[:,:,1][msk<0.5], im2[:,:,2][msk<0.5] = class_color_list[0]\n",
    "            print(path_out+img_path.split('/')[-1])\n",
    "            print(pred[0]['boxes'][i][0].tolist())\n",
    "            \n",
    "            start_point = (int(pred[0]['boxes'][i][0].tolist()), int(pred[0]['boxes'][i][1].tolist()))\n",
    "            end_point = (int(pred[0]['boxes'][i][2].tolist()), int(pred[0]['boxes'][i][3].tolist()))\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 2\n",
    "            \n",
    "            cropped_image = im2[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "            cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            #im2 = cv2.rectangle(im2, start_point, end_point, color, thickness)\n",
    "            #cv2.imwrite(path_out+img_path.split('/')[-1], np.hstack([im,im2]))\n",
    "            cv2.imwrite(path_out+str(counter)+\" \"+img_path.split('/')[-1],cropped_image)\n",
    "            #cv2.imwrite(path_out+str(counter)+\" \"+\"ssssss\"+img_path.split('/')[-1],im2)\n",
    "            counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "571ec862-786a-40b4-813f-2e141cc41ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/madmax/Documents/SK_articles/test_povorotniks/cutted_DATASET/largus//11370_image2245.png', '/home/madmax/Documents/SK_articles/test_povorotniks/cutted_DATASET/largus//11375_image3021.png', '/home/madmax/Documents/SK_articles/test_povorotniks/cutted_DATASET/largus//11380_image52.png', '/home/madmax/Documents/SK_articles/test_povorotniks/cutted_DATASET/largus//11385_image168.png', '/home/madmax/Documents/SK_articles/test_povorotniks/cutted_DATASET/largus//11390_image1118.png']\n",
      "/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/11370_image2245.png\n",
      "189.3506622314453\n",
      "/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/11375_image3021.png\n",
      "58.152645111083984\n",
      "/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/11375_image3021.png\n",
      "191.4287567138672\n",
      "/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/11380_image52.png\n",
      "187.0721435546875\n",
      "/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/11380_image52.png\n",
      "60.562110900878906\n",
      "/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/11385_image168.png\n",
      "189.464599609375\n",
      "/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/11385_image168.png\n",
      "67.95947265625\n",
      "/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/11390_image1118.png\n",
      "61.59777069091797\n"
     ]
    }
   ],
   "source": [
    "output_path = \"turn_lights/\"\n",
    "output_path = \"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/\"\n",
    "imgs.sort()\n",
    "print(imgs)\n",
    "for pth in imgs:   \n",
    "    turn_saver (pth, model,output_path, 0.5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a28ac5f8-f1a5-441b-91c3-dcd623b31c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_1.png average 213.635 max 255 min 154\n",
      "10_2.png average 206.865 max 255 min 130\n",
      "10_3.png average 179.515 max 255 min 109\n",
      "11_1.png average 98.315 max 179 min 74\n",
      "11_2.png average 99.595 max 181 min 74\n",
      "11_3.png average 112.37 max 228 min 78\n",
      "11_4.png average 113.715 max 233 min 79\n",
      "11_5.png average 96.98 max 179 min 72\n",
      "11_6.png average 96.67 max 180 min 72\n",
      "12_1.png average 79.905 max 118 min 57\n",
      "12_2.png average 88.59 max 160 min 53\n",
      "12_3.png average 89.755 max 178 min 51\n",
      "12_4.png average 76.395 max 127 min 49\n",
      "12_5.png average 77.015 max 123 min 52\n",
      "13_1.png average 184.18 max 255 min 110\n",
      "13_2.png average 169.585 max 252 min 97\n",
      "13_3.png average 190.86 max 253 min 126\n",
      "13_4.png average 180.75 max 250 min 109\n",
      "13_5.png average 167.495 max 252 min 96\n",
      "14_1.png average 110.455 max 177 min 83\n",
      "14_2.png average 90.905 max 149 min 60\n",
      "14_3.png average 92.205 max 130 min 74\n",
      "14_4.png average 118.705 max 228 min 76\n",
      "14_5.png average 121.495 max 231 min 69\n",
      "14_6.png average 91.905 max 147 min 66\n",
      "14_7.png average 94.67 max 158 min 68\n",
      "15_1.png average 128.14 max 191 min 94\n",
      "15_2.png average 143.35 max 223 min 104\n",
      "15_3.png average 135.105 max 228 min 90\n",
      "15_4.png average 127.43 max 180 min 94\n",
      "15_5.png average 130.23 max 193 min 102\n",
      "1_1.png average 105.65 max 213 min 62\n",
      "1_2.png average 103.505 max 211 min 62\n",
      "1_3.png average 115.21 max 206 min 74\n",
      "1_4.png average 134.77 max 222 min 82\n",
      "1_5.png average 104.51 max 201 min 65\n",
      "2_1.png average 135.245 max 197 min 98\n",
      "2_2.png average 131.22 max 191 min 94\n",
      "2_3.png average 163.905 max 254 min 110\n",
      "2_4.png average 159.445 max 252 min 102\n",
      "2_5.png average 147.025 max 251 min 92\n",
      "2_6.png average 176.67 max 253 min 107\n",
      "2_7.png average 181.555 max 254 min 109\n",
      "2_8.png average 181.03 max 253 min 108\n",
      "2_9.png average 143.765 max 254 min 90\n",
      "3_1.png average 63.855 max 98 min 45\n",
      "3_2.png average 96.68 max 235 min 45\n",
      "3_3.png average 90.52 max 237 min 41\n",
      "3_4.png average 61.855 max 123 min 43\n",
      "3_5.png average 62.725 max 108 min 43\n",
      "4_1.png average 108.105 max 254 min 68\n",
      "4_2.png average 115.44 max 255 min 68\n",
      "4_3.png average 125.33 max 255 min 70\n",
      "4_4.png average 122.57 max 254 min 71\n",
      "4_5.png average 112.225 max 253 min 71\n",
      "5_1.png average 98.92 max 239 min 49\n",
      "5_2.png average 101.375 max 241 min 49\n",
      "5_3.png average 109.885 max 239 min 55\n",
      "5_4.png average 103.805 max 242 min 51\n",
      "5_5.png average 104.07 max 241 min 52\n",
      "5_6.png average 99.91 max 243 min 49\n",
      "6_1.png average 120.93 max 170 min 95\n",
      "6_2.png average 120.69 max 189 min 94\n",
      "6_3.png average 132.135 max 210 min 98\n",
      "6_4.png average 135.975 max 225 min 101\n",
      "6_5.png average 122.145 max 184 min 96\n",
      "7_1.png average 90.415 max 149 min 47\n",
      "7_2.png average 120.61 max 227 min 62\n",
      "7_3.png average 108.855 max 224 min 55\n",
      "7_4.png average 91.515 max 154 min 49\n",
      "7_5.png average 89.565 max 154 min 51\n",
      "8_1.png average 64.21 max 76 min 58\n",
      "8_2.png average 64.175 max 79 min 56\n",
      "8_3.png average 68.865 max 114 min 57\n",
      "8_4.png average 64.895 max 83 min 56\n",
      "8_5.png average 59.86 max 75 min 54\n",
      "8_6.png average 60.365 max 77 min 54\n",
      "9_1.png average 88.615 max 175 min 61\n",
      "9_2.png average 90.0 max 178 min 62\n",
      "9_3.png average 99.235 max 183 min 65\n",
      "9_4.png average 97.73 max 173 min 62\n",
      "9_5.png average 91.21 max 183 min 64\n",
      "9_6.png average 90.46 max 182 min 63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections_path = \"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/READY/\"\n",
    "det_imgs = []\n",
    "out_gray_image = \"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/GRAY/\"\n",
    "for pth in os.listdir(detections_path):\n",
    "    det_imgs.append(detections_path+\"/\"+pth )\n",
    "det_imgs.sort()\n",
    "\n",
    "#print(det_imgs)\n",
    "for image_pth in det_imgs:\n",
    "    image_light = cv2.imread(image_pth, cv2.IMREAD_GRAYSCALE)\n",
    "    dim_orig = image_light.shape\n",
    "    dim = (20,20)\n",
    "    min_number = 255\n",
    "    image_light = cv2.resize(image_light, dim, interpolation = cv2.INTER_AREA)\n",
    "    image_light = image_light.flatten()\n",
    "    image_light.sort()\n",
    "    image_light = image_light[200:]\n",
    "    image_light = np.reshape(image_light, (20,10))\n",
    "    cv2.imwrite(out_gray_image + image_pth.split('/')[-1], image_light)\n",
    "    for i in range(dim[0]):\n",
    "        for j in range(10):\n",
    "            if (image_light[i][j] < min_number) and (image_light[i][j]>0):\n",
    "                min_number =  image_light[i][j] \n",
    "       \n",
    "    print(image_pth.split('/')[-1] + \" average\", image_light.sum()/200, \"max\", image_light.max(), \"min\", min_number)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "imag1 = cv2.imread(\"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/GRAY/1_3.png\", cv2.IMREAD_GRAYSCALE)    \n",
    "imag2 = cv2.imread(\"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/GRAY/1_4.png\", cv2.IMREAD_GRAYSCALE)       \n",
    "  \n",
    "final_test = imag2-imag1\n",
    "\n",
    "\n",
    "cv2.imwrite(out_gray_image + \"test.png\", final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ff036b71-7aed-4f5e-95bb-68a0f10ffc43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_off1 98244\n",
      "sum_off2 102752\n",
      "sum_on1 152784\n",
      "sum_on2 146240\n",
      "bitwiseoff 67024\n",
      "bitwiseon 111511\n",
      "off, off 0.9987860472957086\n",
      "off, on 0.9783800879982172\n",
      "on, on 0.9791253010726035\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resize_and_count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image_light1 = cv2.imread(\"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/READY/1_1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light2 = cv2.imread(\"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/READY/1_2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light_on1 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights/225_image161.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light_on2 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights/226_image162.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light_on3 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights/227_image163.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light_on4 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights/228_image164.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light3 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights/235_image171.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light4 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights/236_image172.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "output_path = \"turn_lights/\"\n",
    "\n",
    "dim = (20,20)\n",
    "image_light1 = cv2.resize(image_light1, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light2 = cv2.resize(image_light2, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light_on1 = cv2.resize(image_light_on1, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light_on2 = cv2.resize(image_light_on2, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light_on3 = cv2.resize(image_light_on3, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light_on4 = cv2.resize(image_light_on4, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light3 = cv2.resize(image_light3, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light4 = cv2.resize(image_light4, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "cv2.imwrite(output_path + \"image_light2.png\",image_light2)image_light = cv2.imread(image_pth, cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imwrite(output_path + \"image_light_on1.png\",image_light_on1)\n",
    "cv2.imwrite(output_path + \"image_light_on2.png\",image_light_on2)\n",
    "#_,image_light1 = cv2.threshold(image_light1,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#_,image_light2 = cv2.threshold(image_light2,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#_,image_light_on1 = cv2.threshold(image_light_on1,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#_,image_light_on2 = cv2.threshold(image_light_on1,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#_,image_light_on3 = cv2.threshold(image_light_on1,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#_,image_light_on4 = cv2.threshold(image_light_on1,180,255,cv2.THRESH_BINARY)\n",
    "#\n",
    "#_,image_light3 = cv2.threshold(image_light3,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#_,image_light4 = cv2.thrimgeshold(image_light4,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imwrite(output_path + \"image_light_no_gauss.png\",image_light1)\n",
    "\n",
    "# image_light1 = dst = cv2.GaussianBlur(image_light1,(5,5),cv2.BORDER_DEFAULT)\n",
    "# image_light2 = dst = cv2.GaussianBlur(image_light2,(5,5),cv2.BORDER_DEFAULT)\n",
    "# image_light_on1 = dst = cv2.GaussianBlur(image_light_on1,(5,5),cv2.BORDER_DEFAULT)\n",
    "# image_light_on2 = dst = cv2.GaussianBlur(image_light_on2,(5,5),cv2.BORDER_DEFAULT)\n",
    "# image_light_on4 = dst = cv2.GaussianBlur(image_light_on4,(5,5),cv2.BORDER_DEFAULT)\n",
    "# image_light3 = dst = cv2.GaussianBlur(image_light3,(5,5),cv2.BORDER_DEFAULT)\n",
    "# image_light4 = dst = cv2.GaussianBlur(image_light4,(5,5),cv2.BORDER_DEFAULT)\n",
    "\n",
    "# applying kernels to the input image to get the sharpened imageout_src\n",
    "\n",
    "\n",
    "# image_light1 = cv2.filter2D(image_light1,-1,sharpen_filter)\n",
    "# image_light2 = cv2.filter2D(image_light2,-1,sharpen_filter)\n",
    "# image_light_on1 = cv2.filter2D(image_light_on1,-1,sharpen_filter)\n",
    "# image_light_on2 = cv2.filter2D(image_light_on2,-1,sharpen_filter)\n",
    "# image_light_on4 = cv2.filter2D(image_light_on4,-1,sharpen_filter)\n",
    "# image_light3 = cv2.filter2D(image_light3,-1,sharpen_filter)\n",
    "# image_light4 = dst = cv2.filter2D(image_light4,-1,sharpen_filter)\n",
    "\n",
    "# image_light1 = make_20_colors(image_light1)\n",
    "# image_light2 = make_20_colors(image_light2)\n",
    "# image_light_on1 = make_20_colors(image_light_on1)\n",
    "# image_light_on2 = make_20_colors(image_light_on2)\n",
    "# image_light_on3 = make_20_colors(image_light_on3)\n",
    "# image_light_on4 = make_20_colors(image_light_on4)\n",
    "# image_light3 = make_20_colors(image_light3)\n",
    "# image_light4 = make_20_colors(image_light4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sharp_image=cv2.filter2D(image_light1,-1,sharpen_filter)\n",
    "cv2.imwrite(output_path + \"image_light.png\",image_light1)\n",
    "\n",
    "print(\"sum_off1\", image_light1.sum())\n",
    "print(\"sum_off2\", image_light2.sum())\n",
    "print(\"sum_on1\", image_light_on1.sum())\n",
    "print(\"sum_on2\", image_light_on2.sum())\n",
    "\n",
    "\n",
    "#off\n",
    "final_test = cv2.bitwise_and(image_light1, image_light2, mask = None)\n",
    "print(\"bitwiseoff\", final_test.sum())\n",
    "#cv2.imwrite(output_path + \"test_off.png\",final_test)\n",
    "#onsharpen f\n",
    "final_test2 = cv2.bitwise_and(image_light_on1, image_light_on2, mask = None)\n",
    "#cv2.imwrite(output_path + \"test.png_on1.png\",final_test2)\n",
    "#on\n",
    "final_test3 = cv2.bitwise_and(image_light_on3, image_light_on4, mask = None), 1, \n",
    "#cv2.imwrite(output_path + \"test.png_on2.png\",final_test3)\n",
    "print(\"bitwiseon\", final_test3.sum())\n",
    "#off\n",
    "final_test4 = cv2.bitwise_and(image_light3, image_light4, mask = None)\n",
    "\n",
    "final_test5 = cv2.bitwise_and(image_light2, image_light_on4, mask = None)\n",
    "\n",
    "\n",
    "\n",
    "#on - off\n",
    "out1 = final_test2 - final_test\n",
    "\n",
    "# on - on\n",
    "out2 = final_test3 - final_test2\n",
    "\n",
    "#off on\n",
    "out3 =  final_test4 - final_test3\n",
    "\n",
    "dst = cv2.calcHist(image_light1, [0], None, [256], [0,256])\n",
    "dst2 = cv2.calcHist(image_light2, [0], None, [256], [0,256])\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.hist(image_light_on2.ravel(),256,[0,256])\n",
    "\n",
    "base_base = cv2.compareHist( dst, dst2, cv2.HISTCMP_CORREL);\n",
    "print(\"off, off\", base_base)\n",
    "dst3 = cv2.calcHist(image_light_on1, [0], None, [256], [0,256])\n",
    "dst4 = cv2.calcHist(image_light_on2, [0], None, [256], [0,256])\n",
    "\n",
    "base_base2 = cv2.compareHist( dst2, dst3, cv2.HISTCMP_CORREL);\n",
    "print(\"off, on\", base_base2)\n",
    "base_base3 = cv2.compareHist( dst3, dst4, cv2.HISTCMP_CORREL);\n",
    "print(\"on, on\", base_base3)\n",
    "print(type(image_light1))\n",
    "\n",
    "plt.title('Histogram for gray scale image')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#test_?\n",
    "#out4 =  final_test - final_test5  \n",
    "image_light2\n",
    "\n",
    "cv2.imwrite(output_path + \"bitwise_1.png\",final_test)\n",
    "\n",
    "\n",
    "cv2.imwrite(output_path + \"test_off_on_tresh.png\",out1)\n",
    "cv2.imwrite(output_path + \"test_on_off_tresh.png\",out3)\n",
    "#cv2.imwrite(output_path + \"tester.png\",out4)\n",
    "#cv2.imwrite(output_path + \"test.png_on_on_tresh.png\",out2)\n",
    "#cv2.imwrite(output_path + \"test.png_on_off_tresh.png\",thresh3)\n",
    "\n",
    "#cv2.imwrite(output_path + \"out.png\",out)\n",
    "print(\"bitwiseoff\", final_test.sum())\n",
    "print(\"bitwiseon\", final_test3.sum())\n",
    "\n",
    "\n",
    "# counter = 0counter = 0\n",
    "# for i in range(len(final_test)):\n",
    "#     for j in range(len(final_test[0])):\n",
    "#       if final_test[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_off\", counter)\n",
    " \n",
    "# counter = 0\n",
    "# for i in range(len(final_test2)):\n",
    "#     for j in range(len(final_test2[0])):\n",
    "#       if final_test2[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_on\", counter)\n",
    "\n",
    "# counter = 0\n",
    "# for i in range(len(final_test3)):\n",
    "#     for j in range(len(final_test3[0])):\n",
    "#       if final_test[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_off__on\", counter)\n",
    "    \n",
    "# for i in range(len(final_test)):\n",
    "#     for j in range(len(final_test0.9791253010726035[0])):\n",
    "#       if final_test[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_off\", dstcounter)\n",
    " \n",
    "# counter = 0\n",
    "# for i in range(len(final_test2)):\n",
    "#     for j in range(len(final_test2[0])):\n",
    "#       if final_test2[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_on\", counter)\n",
    "\n",
    "# counter = 0\n",
    "# for i in range(len(final_test3)):\n",
    "#     for j in range(len(final_test3[0])):\n",
    "#       if final_test[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_off__on\", counter)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2221505-a3d0-426f-b3e5-95c9e8721f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_to_comparison():\n",
    "    dim = (100,60)\n",
    "    image_light1 = cv2.resize(image_light1, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "def turn_light_status():\n",
    "    print(\"on-off\")\n",
    "    print(\"off-on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "693a3cc9-ee7d-4767-932e-6e643224bf35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_off1 87.4028\n",
      "sum_off2 88.1892\n",
      "sum_on1 80.1748\n",
      "sum_on2 82.9348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rnd turn lights\n",
    "#focus\n",
    "\n",
    "image_light1 = cv2.imread(\"/home/madmax/Documents/SK_articles/to_git/turn_lights/0_image0.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light2 = cv2.imread(\"/home/madmax/Documents/SK_articles/to_git/turn_lights/5_image5.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light_on1 = cv2.imread(\"/home/madmax/Documents/SK_articles/to_git/turn_lights/10_image10.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light_on2 = cv2.imread(\"/home/madmax/Documents/SK_articles/to_git/turn_lights/15_image15.png\", cv2.IMREAD_GRAYSCALE)\n",
    "#image_light_on3 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights_2/1509_image376.png\", cv2.IMREAD_GRAYSCALE)\n",
    "#image_light_on4 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights_2/1510_image377.png\", cv2.IMREAD_GRAYSCALE)\n",
    "#image_light3 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights_2/1520_image388.png\", cv2.IMREAD_GRAYSCALE)\n",
    "#image_light4 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights_2/1521_image389.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "output_path = \"turn_lights/\"\n",
    "\n",
    "dim = (50,50)\n",
    "image_light1 = cv2.resize(image_light1, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light2 = cv2.resize(image_light2, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light_on1 = cv2.resize(image_light_on1, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light_on2 = cv2.resize(image_light_on2, dim, interpolation = cv2.INTER_AREA)\n",
    "#image_light_on3 = cv2.resize(image_light_on3, dim, interpolation = cv2.INTER_AREA)\n",
    "#image_light_on4 = cv2.resize(image_light_on4, dim, interpolation = cv2.INTER_AREA)\n",
    "#image_light3 = cv2.resize(image_light3, dim, interpolation = cv2.INTER_AREA)\n",
    "#image_light4 = cv2.resize(image_light4, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "print(\"sum_off1\", image_light1.sum()/2500)\n",
    "print(\"sum_off2\", image_light2.sum()/2500)\n",
    "print(\"sum_on1\", image_light_on1.sum()/2500)\n",
    "print(\"sum_on2\", image_light_on2.sum()/2500)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.imwrite(output_path + \"test_1.png\",image_light1)\n",
    "cv2.imwrite(output_path + \"test_2.png\",image_light2)\n",
    "cv2.imwrite(output_path + \"test_3.png\",image_light_on1)\n",
    "cv2.imwrite(output_path + \"test_4.png\",image_light_on2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"sum_on3\", image_light_on3.sum())\n",
    "#print(\"sum_on4\", image_light_on4.sum())\n",
    "#print(\"sum_off3\", image_light3.sum())\n",
    "#print(\"sum_off4\", image_light4.sum())\n",
    "\n",
    "\n",
    "##print(\"bitwiseoff\", final_test.sum())\n",
    "#print(\"bitwiseon\", final_test3.sum())\n",
    "\n",
    "# _,image_light1 = cv2.threshold(image_light1,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# _,image_light2 = cv2.threshold(image_light2,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# _,image_light_on1 = cv2.threshold(image_light_on1,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# _,image_light_on2 = cv2.threshold(image_light_on2,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# _,image_light_on3 = cv2.threshold(image_light_on3,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# _,image_light_on4 = cv2.threshold(image_light_on4,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# _,image_light3 = cv2.threshold(image_light3,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# _,image_light4 = cv2.threshold(image_light4,180,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#cv2.imwrite(output_path + \"image_light.png\",image_light3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #off\n",
    "# final_test = cv2.bitwise_and(image_light1, image_light2, mask = None)\n",
    "# #on\n",
    "# final_test2 = cv2.bitwise_and(image_light_on1, image_light_on2, mask = None)\n",
    "# #cv2.imwrite(output_path + \"test.png_on1.png\",final_test2)\n",
    "# #on\n",
    "# final_test3 = cv2.bitwise_and(image_light_on3, image_light_on4, mask = None)\n",
    "# #cv2.imwrite(output_path + \"test.png_on2.png\",final_test3)\n",
    "# #off\n",
    "# final_test4 = cv2.bitwise_and(image_light3, image_light4, mask = None)\n",
    "\n",
    "# final_test5 = cv2.bitwise_and(image_light2, image_light_on4, mask = None)\n",
    "\n",
    "\n",
    "\n",
    "# #on - off\n",
    "# out1 = final_test2 - final_test\n",
    "\n",
    "# # on - on\n",
    "# out2 = final_test3 - final_test2\n",
    "\n",
    "# #off on\n",
    "# out3 =  final_test4 - final_test3\n",
    "\n",
    "\n",
    "\n",
    "# #test_?\n",
    "# out4 =  final_test - final_test5  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cv2.imwrite(output_path + \"test_off_on_tresh.png\",out1)\n",
    "# cv2.imwrite(output_path + \"test_on_off_tresh.png\",out3)\n",
    "# cv2.imwrite(output_path + \"tester.png\",out4)\n",
    "#cv2.imwrite(output_path + \"test.png_on_on_tresh.png\",out2)\n",
    "#cv2.imwrite(output_path + \"test.png_on_off_tresh.png\",thresh3)\n",
    "\n",
    "#cv2.imwrite(output_path + \"out.png\",out)\n",
    "\n",
    "\n",
    "\n",
    "# counter = 0counter = 0\n",
    "# for i in range(len(final_test)):\n",
    "#     for j in range(len(final_test[0])):\n",
    "#       if final_test[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_off\", counter)\n",
    " \n",
    "# counter = 0\n",
    "# for i in range(len(final_test2)):\n",
    "#     for j in range(len(final_test2[0])):\n",
    "#       if final_test2[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_on\", counter)2020 Geely Coolray\n",
    "\n",
    "# counter = 0\n",
    "# for i in range(len(final_test3)):\n",
    "#     for j in range(len(final_test3[0])):\n",
    "#       if final_test[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_off__on\", counter)\n",
    "    \n",
    "# for i in range(len(final_test)):\n",
    "#     for j in range(len(final_test[0])):\n",
    "#       if final_test[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_off\", counter)\n",
    " \n",
    "# counter = 0\n",
    "# for i in range(len(final_test2)):\n",
    "#     for j in range(len(final_test2[0])):\n",
    "#       if final_test2[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_on\", counter)\n",
    "\n",
    "# counter = 0\n",
    "# for i in range(len(final_test3)):\n",
    "#     for j in range(len(final_test3[0])):\n",
    "#       if final_test[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_off__on\", counter)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "53bf183c-9cb9-4266-acea-7a05fe52c86d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_off1 98244\n",
      "sum_off2 102752\n",
      "sum_on1 127367\n",
      "sum_on2 129074\n",
      "bitwiseoff 94541\n",
      "bitwiseon 105663\n"
     ]
    }
   ],
   "source": [
    "#rnd turn lights\n",
    "#uaz\n",
    "image_light1 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights/223_image159.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light2 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights/224_image160.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light_on1 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights_3/1046_image1558.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light_on2 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights_3/1047_image1561.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light_on3 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights_3/1048_image1564.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light_on4 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights_3/1049_image1567.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light3 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights_3/1042_image1545.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image_light4 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights_3/1041_image1542.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "output_path = \"/home/madmax/Documents/SK_articles/turn_light_folders/lights_3/\"\n",
    "\n",
    "dim = (50,50)\n",
    "image_light1 = cv2.resize(image_light1, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light2 = cv2.resize(image_light2, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light_on1 = cv2.resize(image_light_on1, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light_on2 = cv2.resize(image_light_on2, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light_on3 = cv2.resize(image_light_on3, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light_on4 = cv2.resize(image_light_on4, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light3 = cv2.resize(image_light3, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light4 = cv2.resize(image_light4, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "print(\"sum_off1\", image_light1.sum())\n",
    "print(\"sum_off2\", image_light2.sum())\n",
    "print(\"sum_on1\", image_light_on1.sum())\n",
    "print(\"sum_on2\", image_light_on2.sum())\n",
    "\n",
    "cv2.imwrite(output_path + \"full.png\", np.hstack([image_light1,image_light2, image_light_on1,image_light_on2,image_light_on3,image_light_on4,image_light3,image_light4]))\n",
    "\n",
    "# image_light1 = cv2.adaptiveThreshold(image_light1, 255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10)\n",
    "# image_light2 = cv2.adaptiveThreshold(image_light2, 255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10)\n",
    "# image_light_on1 = cv2.adaptiveThreshold(image_light_on1, 255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10)\n",
    "# image_light_on2 = cv2.adaptiveThreshold(image_light_on2, 255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10)\n",
    "# image_light_on3 = cv2.adaptiveThreshold(image_light_on3, 255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10)\n",
    "# image_light_on4 = cv2.adaptiveThreshold(image_light_on4, 255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10)\n",
    "# image_light3 = cv2.adaptiveThreshold(image_light2, 255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10)\n",
    "# image_light4 = cv2.adaptiveThreshold(image_light2, 255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10)\n",
    "\n",
    "\n",
    "# _,image_light1 = cv2.threshold(image_light1,120,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# _,image_light2 = cv2.threshold(image_light2,120,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# _,image_light_on1 = cv2.threshold(image_light_on1,120,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# _,image_light_on2 = cv2.threshold(image_light_on1,120,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# _,image_light_on3 = cv2.threshold(image_light_on1,120,255,cv2.THRESH_BINARY)yfqn\n",
    "\n",
    "# _,image_light_on4 = cv2.threshold(image_light_on1,120,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# _,image_light3 = cv2.threshold(image_light3,120,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# _,image_light4 = cv2.threshold(image_light4,120,255,cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imwrite(output_path + \"image_light.png\",image_light3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#off\n",
    "final_test = cv2.bitwise_and(image_light1, image_light2, mask = None)\n",
    "#cv2.imwrite(output_path + \"test_off.png\",final_test)\n",
    "#on\n",
    "final_test2 = cv2.bitwise_and(image_light_on1, image_light_on2, mask = None)\n",
    "#cv2.imwrite(output_path + \"test.png_on1.png\",final_test2)\n",
    "#on\n",
    "final_test3 = cv2.bitwise_and(image_light_on3, image_light_on4, mask = None)\n",
    "#cv2.imwrite(output_path + \"test.png_on2.png\",final_test3)\n",
    "#off\n",
    "final_test4 = cv2.bitwise_and(image_light3, image_light4, mask = None)\n",
    "\n",
    "final_test5 = cv2.bitwise_and(image_light2, image_light_on4, mask = None)image_light = cv2.imread(image_pth, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "\n",
    "#on - off\n",
    "out1 = final_test2 - final_test\n",
    "\n",
    "# on - on\n",
    "out2 = final_test3 - final_test2\n",
    "#off on\n",
    "out3 =  final_test4 - final_test3\n",
    "\n",
    "\n",
    "\n",
    "#test_?\n",
    "out4 =  final_test - final_test5  \n",
    "dim = (50,50)\n",
    "image_light1 = cv2.resize(image_light1, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light2 = cv2.resize(image_light2, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light_on1 = cv2.resize(image_light_on1, dim, interpolation = cv2.INTER_AREA)\n",
    "image_light_on2 = cv2.resize(image_light_on2, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.imwrite(output_path + \"test_on_off_tresh.png\",out1)\n",
    "cv2.imwrite(output_path + \"test_off_on_tresh.png\",out3)\n",
    "cv2.imwrite(output_path + \"tester.png\",out4)\n",
    "\n",
    "\n",
    "print(\"bitwiseoff\", final_test4.sum())\n",
    "print(\"bitwiseon\", final_test2.sum())\n",
    "#cv2.imwrite(output_path + \"test.png_on_on_tresh.png\",out2)\n",
    "#cv2.imwrite(output_path + \"test.png_on_off_tresh.png\",thresh3)\n",
    "\n",
    "#cv2.imwrite(output_path + \"out.png\",out)\n",
    "\n",
    "\n",
    "\n",
    "# counter = 0counter = 0\n",
    "# for i in range(len(final_test)):\n",
    "#     for j in range(len(final_test[0])):\n",
    "#       if final_test[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_off\", counter)\n",
    " \n",
    "# counter = 0\n",
    "# for i in range(len(final_test2)):\n",
    "#     for j in range(len(final_test2[0])):\n",
    "#       if final_test2[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_on\", counter)\n",
    "\n",
    "# counter = 0\n",
    "# for i in range(len(final_test3)):\n",
    "#     for j in range(len(final_test3[0])):\n",
    "#       if final_test[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_off__on\", counter)\n",
    "    \n",
    "# for i in range(len(final_test)):\n",
    "#     for j in range(len(final_iimage_light1m2test[0])):\n",
    "#       if final_test[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_off\", counter)\n",
    " \n",
    "# counter = 0\n",
    "# for i in range(len(final_test2)):\n",
    "#     for j in range(len(final_test2[0])):\n",
    "#       if final_test2[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_on\", counter)120\n",
    "\n",
    "# counter = 0image_light1 = cv2.imread(\"/home/madmax/Documents/SK_articles/turn_light_folders/lights/223_image159.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# for i in range(len(final_test3)):\n",
    "#     for j in range(len(final_test3[0])):\n",
    "#       if final_test[i][j] !=0:\n",
    "#         counter +=1\n",
    "# print(\"test_off__on\", counter)\n",
    "    \n",
    "image_light = cv2.imread(image_pth, cv2.IMREAD_GRAYSCALE)\n",
    "#cv2.imwrite(output_path + \"full.png\", np.hstack([image_light1,image_light2, image_light_on1,image_light_on2,image_light_on3,image_light_on4,image_light3,image_light4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fbb0ca9-5347-4ed7-ab33-1f8c6690994a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "847ccf1a-c394-416b-992b-91fbf0eaa7fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "images is expected to be a list of 3d tensors of shape [C, H, W], got torch.Size([1, 3, 200, 200])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(x, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#x = list(image.to(device) for image in x)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m torch_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Export the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mexport(model,               \u001b[38;5;66;03m# model being run\u001b[39;00m\n\u001b[1;32m     11\u001b[0m                   x,                         \u001b[38;5;66;03m# model input (or a tuple for multiple inputs)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuper_resolution.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;66;03m# where to save the model (can be a file or file-like object)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m     26\u001b[0m                   })\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py:83\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_assert(\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28mlen\u001b[39m(val) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpecting the last two dimensions of the Tensor to be H and W instead got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     80\u001b[0m     )\n\u001b[1;32m     81\u001b[0m     original_image_sizes\u001b[38;5;241m.\u001b[39mappend((val[\u001b[38;5;241m0\u001b[39m], val[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m---> 83\u001b[0m images, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Check for degenerate boxes\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# TODO: Move this to a function\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/detection/transform.py:128\u001b[0m, in \u001b[0;36mGeneralizedRCNNTransform.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    125\u001b[0m target_index \u001b[38;5;241m=\u001b[39m targets[i] \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages is expected to be a list of 3d tensors of shape [C, H, W], got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    129\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize(image)\n\u001b[1;32m    130\u001b[0m image, target_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize(image, target_index)\n",
      "\u001b[0;31mValueError\u001b[0m: images is expected to be a list of 3d tensors of shape [C, H, W], got torch.Size([1, 3, 200, 200])"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "batch_size = 1\n",
    "#x = torch.randn(batch_size,200, 200, requires_grad=True)\n",
    "x = torch.rand(1, 3, 200, 200)\n",
    "x.to(device)\n",
    "x = torch.as_tensor(x, dtype=torch.float32).unsqueeze(0)\n",
    "#x = list(image.to(device) for image in x)\n",
    "torch_out = model(x)\n",
    "# Export the model\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"super_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=12,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],\n",
    "                  \n",
    "                  # the model's input names\n",
    "                  output_names = [\"bbox_coords\", \"bbox_labels\", \"bbox_scores\", \"bbox_masks\"], # the model's output names\n",
    "                  dynamic_axes={\n",
    "                    \"images_tensors\": [0, 1, 2, 3],\n",
    "                    \"boxes\": [0, 1],\n",
    "                    \"labels\": [0],\n",
    "                    \"scores\": [0],\n",
    "                    \"masks\": [0, 1, 2, 3],\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbc1646f-f3cd-416a-8367-0eb0140382c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(\"super_resolution.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6892f056-9c7b-44eb-bc64-c0016c6a0eea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 07:42:08.459740036 [W:onnxruntime:, graph.cc:3490 CleanUnusedInitializersAndNodeArgs] Removing initializer '3512'. It is not used by any node and should be removed from the model.\n",
      "2023-05-12 07:42:08.459757049 [W:onnxruntime:, graph.cc:3490 CleanUnusedInitializersAndNodeArgs] Removing initializer '3510'. It is not used by any node and should be removed from the model.\n",
      "2023-05-12 07:42:09.065544544 [W:onnxruntime:, graph.cc:3490 CleanUnusedInitializersAndNodeArgs] Removing initializer '3512'. It is not used by any node and should be removed from the model.\n",
      "2023-05-12 07:42:09.065562424 [W:onnxruntime:, graph.cc:3490 CleanUnusedInitializersAndNodeArgs] Removing initializer '3510'. It is not used by any node and should be removed from the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 200, 200)\n",
      "(1, 1, 200, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([], shape=(0, 4), dtype=float32),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=float32),\n",
       " array([], shape=(0, 1, 200, 200), dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from onnxruntime import InferenceSession\n",
    "import numpy as np\n",
    "\n",
    "#images = list(image.to(device) for image in images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(images.numpy().shape)yfqn\n",
    "\n",
    "print(x.detach().cpu().numpy().shape)\n",
    "\n",
    "session = InferenceSession(\"super_resolution.onnx\")\n",
    "session.run(None, {\"input\": x.detach().cpu().numpy()} )\n",
    "\n",
    "# Print Result \n",
    "#predicted, actual = classes[outputs[0][0].argmax(0)], classes[y]\n",
    "#print(f'Predicted: \"{predicted}\", Actual: \"/home/madmax/Documents/SK_articles/final_test/coco_car_test/294502103/original.png{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c5d6c9a7-768d-4a1f-a57f-f88aa9713a69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 08:41:49.150746323 [W:onnxruntime:, graph.cc:3490 CleanUnusedInitializersAndNodeArgs] Removing initializer '3515'. It is not used by any node and should be removed from the model.\n",
      "2023-05-12 08:41:49.150766126 [W:onnxruntime:, graph.cc:3490 CleanUnusedInitializersAndNodeArgs] Removing initializer '3517'. It is not used by any node and should be removed from the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[162.39151 ,  87.1688  , 182.41376 , 105.461586],\n",
       "        [158.09389 ,  83.88535 , 182.14897 , 116.56594 ],\n",
       "        [158.47466 ,  82.94246 , 182.42885 , 116.08284 ],\n",
       "        [162.15977 ,  87.08386 , 181.64857 , 105.84416 ],\n",
       "        [162.97716 ,  87.7665  , 182.27946 , 105.40333 ]], dtype=float32),\n",
       " array([3, 4, 3, 4, 2], dtype=int64),\n",
       " array([0.2826203 , 0.21250182, 0.16794051, 0.11489729, 0.10327099],\n",
       "       dtype=float32),\n",
       " array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch, torchvision\n",
    "from onnxruntime import InferenceSession\n",
    "\n",
    "#model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "x = torch.rand(1, 3, 200, 200)\n",
    "images = cv2.imread(\"/home/madmax/Documents/SK_articles/final_test/coco_car_test/294502103/original.png\")\n",
    "images = cv2.resize(images, (200,200), cv2.INTER_LINEAR)\n",
    "images = torch.as_tensor(images, dtype=torch.float32).unsqueeze(0)\n",
    "images=images.swapaxes(1, 3).swapaxes(2, 3)\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,  # ONNX requires fixed input size\n",
    "    \"test-mask-rcnn-export.onnx\",\n",
    "    do_constant_folding=True,\n",
    "    dynamic_axes={\n",
    "        \"images_tensors\": [0, 1, 2, 3],\n",
    "        \"boxes\": [0, 1],\n",
    "        \"labels\": [0],\n",
    "        \"scores\": [0],\n",
    "        \"masks\": [0, 1, 2, 3],\n",
    "    },\n",
    "    # dynamic_axes={\"input_image\": {0: \"sequence\"}, \"output\": {0: \"sequence\"}},\n",
    "    input_names=[\"input_image\"],\n",
    "    output_names=[\"bbox_coords\", \"bbox_labels\", \"bbox_scores\", \"bbox_masks\"],\n",
    "    opset_version=11,  # opset_version 11 required for Mask R-CNN\n",
    ")\n",
    "\n",
    "session = InferenceSession(\"test-mask-rcnn-export.onnx\")\n",
    "session.run(None, {\"input_image\": images.detach().cpu().numpy()} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "2e94985c-e96e-42b9-a2dc-355f2a03fe20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_turn_light_state(img1,img2,img3,img4):\n",
    "    \n",
    "   \n",
    "    final_count = 0\n",
    "    #final_test1 = cv2.bitwise_and(image_light1, image_light2, mask = None)\n",
    "    #final_test2 = cv2.bitwise_and(image_light3, image_light4, mask = None)\n",
    "    #final_count = (int(final_test2.sum()) - int(final_test1.sum()))\n",
    "    \n",
    "    \n",
    "    final_test1 = (int(image_light3.sum() + image_light4.sum()))/2\n",
    "    final_test2 = (int(image_light1.sum() + image_light2.sum()))/2 \n",
    "    \n",
    "    final_count =  final_test1- final_test2\n",
    "    \n",
    "    print(final_test1)\n",
    "    print(final_test2)\n",
    "    print(final_count)\n",
    "    #print(final_test2.sum()/5)\n",
    "    print(\"------------\")\n",
    "    #final_test1.sum()/4)\n",
    "    if (final_count > 0) and (final_count > 2000):\n",
    "        return \"ON\"\n",
    "    elif (final_count < 0) and (final_count < -2000):\n",
    "        return \"OFF\"\n",
    "    else:\n",
    "        return \"NO_STATE_CHANGED\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "e68248af-4421-4dab-85c7-b6287b1ddcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out_lights = \"/home/madmax/Documents/SK_articles/turn_light_folders/all_lights/\"\n",
    "import os\n",
    "path_in=\"/home/madmax/Documents/SK_articles/turn_light_folders/lights_2/\"\n",
    "\n",
    "imgs=[]\n",
    "for pth in os.listdir(path_in):\n",
    "    imgs.append(path_in+\"/\"+pth)\n",
    "imgs.sort()\n",
    "a = np.array(imgs).reshape(19,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "16608326-7ddb-443f-964a-f315750a6fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "151512.0\n",
      "158041.5\n",
      "-6529.5\n",
      "------------\n",
      "1\n",
      "156336.0\n",
      "152994.5\n",
      "3341.5\n",
      "------------\n",
      "2\n",
      "183348.0\n",
      "174575.5\n",
      "8772.5\n",
      "------------\n",
      "3\n",
      "174750.5\n",
      "177107.0\n",
      "-2356.5\n",
      "------------\n",
      "4\n",
      "146065.0\n",
      "165133.5\n",
      "-19068.5\n",
      "------------\n",
      "5\n",
      "149259.0\n",
      "152242.0\n",
      "-2983.0\n",
      "------------\n",
      "6\n",
      "141120.5\n",
      "146464.5\n",
      "-5344.0\n",
      "------------\n",
      "7\n",
      "144047.5\n",
      "140547.5\n",
      "3500.0\n",
      "------------\n",
      "8\n",
      "147231.0\n",
      "147628.0\n",
      "-397.0\n",
      "------------\n",
      "9\n",
      "146501.0\n",
      "149319.0\n",
      "-2818.0\n",
      "------------\n",
      "10\n",
      "123232.0\n",
      "129508.5\n",
      "-6276.5\n",
      "------------\n",
      "11\n",
      "124626.0\n",
      "125856.0\n",
      "-1230.0\n",
      "------------\n",
      "12\n",
      "109520.5\n",
      "125772.5\n",
      "-16252.0\n",
      "------------\n",
      "13\n",
      "154318.0\n",
      "154305.5\n",
      "12.5\n",
      "------------\n",
      "14\n",
      "147343.5\n",
      "152886.5\n",
      "-5543.0\n",
      "------------\n",
      "15\n",
      "126434.0\n",
      "136750.5\n",
      "-10316.5\n",
      "------------\n",
      "16\n",
      "152181.0\n",
      "136602.0\n",
      "15579.0\n",
      "------------\n",
      "17\n",
      "141420.5\n",
      "182230.0\n",
      "-40809.5\n",
      "------------\n",
      "18\n",
      "136847.5\n",
      "129926.0\n",
      "6921.5\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "dim = (50,50)\n",
    "for i in a:\n",
    "    #print(i)\n",
    "    print(counter)\n",
    "    image_light1 = cv2.imread(i[0], cv2.IMREAD_GRAYSCALE)\n",
    "    image_light2 = cv2.imread(i[1], cv2.IMREAD_GRAYSCALE)\n",
    "    image_light3 = cv2.imread(i[2], cv2.IMREAD_GRAYSCALE)\n",
    "    image_light4 = cv2.imread(i[3], cv2.IMREAD_GRAYSCALE)\n",
    "    image_light1 = cv2.resize(image_light1, dim, interpolation = cv2.INTER_AREA)\n",
    "    image_light2 = cv2.resize(image_light2, dim, interpolation = cv2.INTER_AREA)\n",
    "    image_light3 = cv2.resize(image_light3, dim, interpolation = cv2.INTER_AREA)\n",
    "    image_light4 = cv2.resize(image_light4, dim, interpolation = cv2.INTER_AREA)\n",
    "    str1 = count_turn_light_state(image_light1,image_light2,image_light3,image_light4)1.88\n",
    "    \n",
    "    cv2.imwrite(path_out_lights+str(counter)+str1 + \".png\", np.hstack([image_light1,image_light2,image_light3,image_light4]))\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a66374c-7a69-4d61-8e30-029cfde5b6a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m from_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/READY/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m phare_imgs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pth \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(from_pairs):\n\u001b[1;32m     18\u001b[0m     phare_imgs\u001b[38;5;241m.\u001b[39mappend(from_pairs\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mpth )\n\u001b[1;32m     19\u001b[0m phare_imgs\u001b[38;5;241m.\u001b[39msort()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#make pairs\n",
    "\n",
    "def unite_and_save (pth1, pth2, pair_path, name, counter):\n",
    "    image_1 = cv2.imread(pth1, cv2.IMREAD_GRAYSCALE)\n",
    "    image_2 = cv2.imread(pth2, cv2.IMREAD_GRAYSCALE)\n",
    "    imageSize=[20,20]\n",
    "    image_1 = cv2.resize(image_1, imageSize, cv2.INTER_LINEAR)\n",
    "    image_2 = cv2.resize(image_2, imageSize, cv2.INTER_LINEAR)\n",
    "    cv2.imwrite(pair_path+name + '_'+ str(counter)+\".png\", np.hstack([image_1,image_2]))\n",
    "\n",
    "\n",
    "\n",
    "pair_path = \"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/PAIRS/\"\n",
    "from_pairs = \"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/READY/\"\n",
    "phare_imgs = []\n",
    "\n",
    "for pth in os.listdir(from_pairs):\n",
    "    phare_imgs.append(from_pairs+\"/\"+pth )\n",
    "phare_imgs.sort()\n",
    "\n",
    "phare_imgs_2 = phare_imgs.copy()\n",
    "phare_imgs_2.append(phare_imgs_2[0])\n",
    "phare_imgs_2.pop(0)\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(phare_imgs)):\n",
    "    \n",
    "    if (phare_imgs[i].split('/')[-1].split('_')[0] == phare_imgs_2[i].split('/')[-1].split('_')[0]):\n",
    "        print(phare_imgs[i])\n",
    "        print(phare_imgs_2[i])\n",
    "        unite_and_save(phare_imgs[i], phare_imgs_2[i], pair_path, phare_imgs[i].split('/')[-1].split('_')[0], counter)\n",
    "        counter +=1\n",
    "    else:\n",
    "        counter = 0\n",
    "    \n",
    "        print('-------')\n",
    "#cv2.imwrite(path_out+img_path.split('/')[-1], np.hstack([im,im2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec3ccee0-3489-43af-b015-d018b6d09d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train\n",
    "class_1 = \"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/PAIRS_CLASSES/NOT_CHANGE/\"\n",
    "class_2 = \"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/PAIRS_CLASSES/OFF_ON/\"\n",
    "class_3 = \"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/PAIRS_CLASSES/ON_OFF/\"\n",
    "\n",
    "\n",
    "for pth in os.listdir(class_1):\n",
    "    image_1 = cv2.imread(class_1+pth, cv2.IMREAD_GRAYSCALE)\n",
    "    #image_1 = image_1.flatten()\n",
    "    #buf_average = []\n",
    "    #image_crop1 = image_1[0:20, 0:20]\n",
    "    #image_crop2 = image_1[0:20, 20:40]\n",
    "    #buf_average.append(image_crop1.sum()/200)\n",
    "    #buf_average.append(image_crop2.sum()/200)\n",
    "    #X_train.append(buf_average)\n",
    "    X_train.append(image_1)\n",
    "    y_train.append(0)\n",
    "for pth in os.listdir(class_2):\n",
    "    image_1 = cv2.imread(class_2+pth, cv2.IMREAD_GRAYSCALE)\n",
    "    #image_1 = image_1.flatten()\n",
    "    #buf_average = []\n",
    "    #image_crop1 = image_1[0:20, 0:20]\n",
    "    #image_crop2 = image_1[0:20, 20:40]\n",
    "    #buf_average.append(image_crop1.sum()/200)\n",
    "    #buf_average.append(image_crop2.sum()/200)\n",
    "    #X_train.append(buf_average)\n",
    "    X_train.append(image_1)\n",
    "    y_train.append(1)\n",
    "for pth in os.listdir(class_3):\n",
    "    image_1 = cv2.imread(class_3+pth, cv2.IMREAD_GRAYSCALE)\n",
    "    #image_1 = image_1.flatten()\n",
    "    #buf_average = []\n",
    "    #image_crop1 = image_1[0:20, 0:20]\n",
    "    #image_crop2 = image_1[0:20, 20:40]\n",
    "    #buf_average.append(image_crop1.sum()/200)\n",
    "    #buf_average.append(image_crop2.sum()/200)\n",
    "    #X_train.append(buf_average)\n",
    "    X_train.append(image_1)\n",
    "    y_train.append(2)\n",
    "\n",
    "    \n",
    "    \n",
    "#test\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "class_1_t = \"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/PAIRS_CLASSES/TEST/NOT_CHANGED/\"\n",
    "class_2_t = \"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/PAIRS_CLASSES/TEST/OFF_ON/\"\n",
    "class_3_t = \"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/PAIRS_CLASSES/TEST/ON_OFF/\"\n",
    "for pth in os.listdir(class_1_t):\n",
    "    image_1 = cv2.imread(class_1_t+pth, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    #buf_average = []\n",
    "    #image_crop1 = image_1[0:20, 0:20]\n",
    "    #image_crop2 = image_1[0:20, 20:40]\n",
    "    \n",
    "    #buf_average.append(image_crop1.sum()/200)\n",
    "    #buf_average.append(image_crop2.sum()/200)    \n",
    "    #X_test.append(buf_average)\n",
    "    \n",
    "    \n",
    "    image_1 = image_1.flatten()\n",
    "    X_test.append(image_1)\n",
    "    y_test.append(0)\n",
    "for pth in os.listdir(class_2_t):\n",
    "    #buf_average = []\n",
    "    image_1 = cv2.imread(class_2_t+pth, cv2.IMREAD_GRAYSCALE)\n",
    "    image_1 = image_1.flatten()\n",
    "    #image_crop1 = image_1[0:20, 0:20]\n",
    "    #image_crop2 = image_1[0:20, 20:40]\n",
    "    #buf_average.append(image_crop1.sum()/200)\n",
    "    #buf_average.append(image_crop2.sum()/200)\n",
    "    #X_test.append(buf_average)\n",
    "    X_test.append(image_1)\n",
    "    y_test.append(1)\n",
    "for pth in os.listdir(class_3_t):\n",
    "    #buf_average = []\n",
    "    image_1 = cv2.imread(class_3_t+pth, cv2.IMREAD_GRAYSCALE)\n",
    "    image_1 = image_1.flatten()\n",
    "    #image_crop1 = image_1[0:20, 0:20]\n",
    "    #image_crop2 = image_1[0:20, 20:40]\n",
    "    #buf_average.append(image_crop1.sum()/200)\n",
    "    #buf_average.append(image_crop2.sum()/200)\n",
    "    #X_test.append(buf_average)\n",
    "    X_test.append(image_1)\n",
    "    y_test.append(2)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# print(os.listdir(class_1_t)[0])\n",
    "    \n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# class_1_t = \"/home/madmax/Documents/SK_articles/test_pov\n",
    "# gnb = GaussianNB()\n",
    "# gnb.fit(X_train, y_train)\n",
    " \n",
    "# # making predictions on the testing set\n",
    "# y_pred = gnb.predict(X_test)\n",
    " \n",
    "# # comparing actual response values (y_test) with predicted response values (y_pred)\n",
    "# from sklearn import metrics\n",
    "# print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "59f32905-db1c-480e-8080-48de3af572ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#image_light.sum()/200\n",
    "# image_1 = cv2.imread(\"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/PAIRS_CLASSES/NOT_CHANGE/1_0.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# #image_2 = image_1.copy()\n",
    "\n",
    "# print(image_crop2.shape)\n",
    "\n",
    "# out = \"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/\"\n",
    "# cv2.imwrite(out + 'test1.png', image_crop1)\n",
    "# cv2.imwrite(out + 'test2.png', image_crop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "cdf15c7b-6842-4b5f-81a7-49ab840248aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "\n",
    "clf = HistGradientBoostingClassifier(learning_rate = 0.5, max_iter=1000,min_samples_leaf = 14).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8832f1ba-3fd2-4157-b6cd-00e0580dec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madmax/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/madmax/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "clf = OutputCodeClassifier(LinearSVC(random_state=0), code_size=2, random_state=0)\n",
    "clf.fit(X_train, y_train).predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bdd0c7f-1425-46b5-9892-fe3402c0d131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#laplacian = cv.Laplacian(img,cv.CV_64F)\n",
    "#\n",
    "image_1 = cv2.imread(\"/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/PAIRS_CLASSES/NOT_CHANGE/12_3.png\", cv2.IMREAD_GRAYSCALE)\n",
    "out = \"/home/madmax/Documents/SK_articles/test_povorotniks/\"\n",
    "#laplacian = cv2.Laplacian(image_1,cv2.CV_64F)\n",
    "sobel = cv2.Sobel(image_1,cv2.CV_64F,1,0,ksize=5)\n",
    "cv2.imwrite(out + \"original.png\", image_1)\n",
    "cv2.imwrite(out + \"sobel.png\", sobel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "790e0dc8-3d22-4eb0-bfeb-44d90b10b29c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106.0\n"
     ]
    }
   ],
   "source": [
    "# Create subplots with 1 row and 2 columns\n",
    "\n",
    "cv2.imwrite(out + \"original.png\", image_1)\n",
    "\n",
    "result = cv2.fastNlMeansDenoising(image_1, None, 20, 10, 21) \n",
    "cv2.imwrite(out + \"fastNlMeansDenoisingColored.png\", result)\n",
    "\n",
    "hist = cv2.calcHist([result], [0], None, [256], [0, 256])\n",
    "print(hist.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "03ef28ce-ff98-45be-9736-86eaccc8bee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "210.84000000000015\n",
      "\n",
      "[[116.04  65.48  41.36   1.96]\n",
      " [ 85.04 102.88 135.8   50.52]\n",
      " [ 42.84  56.12  60.04  29.56]\n",
      " [ 31.    37.68  35.48  19.84]]\n",
      "[[59.96 55.6  38.12  8.48]\n",
      " [48.28 56.8  62.08 40.84]\n",
      " [52.04 50.28 59.48 29.6 ]\n",
      " [44.6  34.84 39.08 20.72]]\n",
      "[[ 5.608e+01  9.880e+00  3.240e+00 -6.520e+00]\n",
      " [ 3.676e+01  4.608e+01  7.372e+01  9.680e+00]\n",
      " [-9.200e+00  5.840e+00  5.600e-01 -4.000e-02]\n",
      " [-1.360e+01  2.840e+00 -3.600e+00 -8.800e-01]]\n",
      "[[-5.608e+01 -9.880e+00 -3.240e+00  6.520e+00]\n",
      " [-3.676e+01 -4.608e+01 -7.372e+01 -9.680e+00]\n",
      " [ 9.200e+00 -5.840e+00 -5.600e-01  4.000e-02]\n",
      " [ 1.360e+01 -2.840e+00  3.600e+00  8.800e-01]]\n",
      "ON OFF\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "image_1_full = cv2.imread('/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/PAIRS_CLASSES/ON_OFF/3_2.png', cv2.IMREAD_GRAYSCALE)\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "image_gray_1 = image_1_full[0:20, 0:20]\n",
    "image_gray_2 = image_1_full[0:20, 20:40]\n",
    "\n",
    "\n",
    "cv2.imwrite(out + \"original1.png\", image_gray_1)\n",
    "cv2.imwrite(out + \"original2.png\", image_gray_2)\n",
    "#image_gray_1 = image_gray_1/255\n",
    "#image_gray_1 = image_gray_1*255\n",
    "cv2.imwrite(out + \"cut_1.png\", image_gray_1)\n",
    "cv2.imwrite(out + \"cut_2.png\", image_gray_2)\n",
    "\n",
    "\n",
    "m = nn.AvgPool2d((5, 5))\n",
    "output = m(torch.tensor([image_gray_1], dtype=torch.float64))\n",
    "print(type(torch.tensor([image_gray_2])))\n",
    "\n",
    "output2 = m(torch.tensor([image_gray_2], dtype=torch.float64))\n",
    "\n",
    "print(output.numpy()[0].sum()-output2.numpy()[0].sum())\n",
    "print()\n",
    "\n",
    "\n",
    "cv2.imwrite(out + \"cut_1.png\", output.numpy()[0])\n",
    "cv2.imwrite(out + \"cut_2.png\", output2.numpy()[0])\n",
    "print(output.numpy()[0])\n",
    "print(output2.numpy()[0])\n",
    "\n",
    "sum1 = output.numpy()[0]-output2.numpy()[0]\n",
    "\n",
    "sum2 =  output2.numpy()[0] - output.numpy()[0]\n",
    "#black = np.zeros(shape=output.numpy()[0], dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite(out + \"cut_3.png\",sum2)\n",
    "\n",
    "print(sum1)\n",
    "print(sum2)\n",
    "\n",
    "if sum1.sum() > 100:\n",
    "    print(\"ON OFF\")\n",
    "if sum1.sum() < -100:\n",
    "    print(\"OFF ON\")\n",
    "if sum1.sum() < 100 and sum1.sum() > -100:\n",
    "    print(\"NOT CHANGED\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f487f0c-2bd0-4f02-a116-39c6e99f04cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "0\n",
      "0.0 1.0 0.8571428571428571\n",
      "0.6190476190476191\n",
      "-----------\n",
      "1\n",
      "0.0 1.0 0.8571428571428571\n",
      "0.6190476190476191\n",
      "-----------\n",
      "2\n",
      "0.0 1.0 0.8571428571428571\n",
      "0.6190476190476191\n",
      "-----------\n",
      "3\n",
      "0.0 1.0 0.8571428571428571\n",
      "0.6190476190476191\n",
      "-----------\n",
      "4\n",
      "0.0 1.0 0.8571428571428571\n",
      "0.6190476190476191\n",
      "-----------\n",
      "5\n",
      "0.0 1.0 0.8571428571428571\n",
      "0.6190476190476191\n",
      "-----------\n",
      "6\n",
      "0.0 1.0 0.8571428571428571\n",
      "0.6190476190476191\n",
      "-----------\n",
      "7\n",
      "0.0 1.0 0.8571428571428571\n",
      "0.6190476190476191\n",
      "-----------\n",
      "8\n",
      "0.0 1.0 0.8571428571428571\n",
      "0.6190476190476191\n",
      "-----------\n",
      "9\n",
      "0.0 1.0 0.8571428571428571\n",
      "0.6190476190476191\n",
      "-----------\n",
      "10\n",
      "0.0 1.0 0.8571428571428571\n",
      "0.6190476190476191\n",
      "-----------\n",
      "11\n",
      "0.0 1.0 0.8571428571428571\n",
      "0.6190476190476191\n",
      "-----------\n",
      "12\n",
      "0.0 1.0 0.8571428571428571\n",
      "0.6190476190476191\n",
      "-----------\n",
      "13\n",
      "0.07142857142857142 1.0 0.8571428571428571\n",
      "0.6428571428571428\n",
      "-----------\n",
      "14\n",
      "0.07142857142857142 1.0 0.8571428571428571\n",
      "0.6428571428571428\n",
      "-----------\n",
      "15\n",
      "0.07142857142857142 1.0 0.8571428571428571\n",
      "0.6428571428571428\n",
      "-----------\n",
      "16\n",
      "0.07142857142857142 1.0 0.8571428571428571\n",
      "0.6428571428571428\n",
      "-----------\n",
      "17\n",
      "0.07142857142857142 1.0 0.8571428571428571\n",
      "0.6428571428571428\n",
      "-----------\n",
      "18\n",
      "0.07142857142857142 1.0 0.8571428571428571\n",
      "0.6428571428571428\n",
      "-----------\n",
      "19\n",
      "0.07142857142857142 1.0 0.8571428571428571\n",
      "0.6428571428571428\n",
      "-----------\n",
      "20\n",
      "0.07142857142857142 1.0 0.8571428571428571\n",
      "0.6428571428571428\n",
      "-----------\n",
      "21\n",
      "0.14285714285714285 1.0 0.8571428571428571\n",
      "0.6666666666666666\n",
      "-----------\n",
      "22\n",
      "0.14285714285714285 1.0 0.8571428571428571\n",
      "0.6666666666666666\n",
      "-----------\n",
      "23\n",
      "0.14285714285714285 0.9285714285714286 0.8571428571428571\n",
      "0.6428571428571428\n",
      "-----------\n",
      "24\n",
      "0.14285714285714285 0.9285714285714286 0.8571428571428571\n",
      "0.6428571428571428\n",
      "-----------\n",
      "25\n",
      "0.21428571428571427 0.9285714285714286 0.8571428571428571\n",
      "0.6666666666666666\n",
      "-----------\n",
      "26\n",
      "0.21428571428571427 0.9285714285714286 0.8571428571428571\n",
      "0.6666666666666666\n",
      "-----------\n",
      "27\n",
      "0.21428571428571427 0.9285714285714286 0.8571428571428571\n",
      "0.6666666666666666\n",
      "-----------\n",
      "28\n",
      "0.21428571428571427 0.9285714285714286 0.8571428571428571\n",
      "0.6666666666666666\n",
      "-----------\n",
      "29\n",
      "0.2857142857142857 0.9285714285714286 0.8571428571428571\n",
      "0.6904761904761906\n",
      "-----------\n",
      "30\n",
      "0.2857142857142857 0.9285714285714286 0.7857142857142857\n",
      "0.6666666666666666\n",
      "-----------\n",
      "31\n",
      "0.2857142857142857 0.9285714285714286 0.7857142857142857\n",
      "0.6666666666666666\n",
      "-----------\n",
      "32\n",
      "0.2857142857142857 0.9285714285714286 0.7857142857142857\n",
      "0.6666666666666666\n",
      "-----------\n",
      "33\n",
      "0.2857142857142857 0.9285714285714286 0.7857142857142857\n",
      "0.6666666666666666\n",
      "-----------\n",
      "34\n",
      "0.2857142857142857 0.9285714285714286 0.7857142857142857\n",
      "0.6666666666666666\n",
      "-----------\n",
      "35\n",
      "0.2857142857142857 0.9285714285714286 0.7857142857142857\n",
      "0.6666666666666666\n",
      "-----------\n",
      "36\n",
      "0.2857142857142857 0.9285714285714286 0.7857142857142857\n",
      "0.6666666666666666\n",
      "-----------\n",
      "37\n",
      "0.2857142857142857 0.9285714285714286 0.7857142857142857\n",
      "0.6666666666666666\n",
      "-----------\n",
      "38\n",
      "0.2857142857142857 0.9285714285714286 0.7857142857142857\n",
      "0.6666666666666666\n",
      "-----------\n",
      "39\n",
      "0.2857142857142857 0.9285714285714286 0.7857142857142857\n",
      "0.6666666666666666\n",
      "-----------\n",
      "40\n",
      "0.2857142857142857 0.9285714285714286 0.7857142857142857\n",
      "0.6666666666666666\n",
      "-----------\n",
      "41\n",
      "0.2857142857142857 0.9285714285714286 0.7857142857142857\n",
      "0.6666666666666666\n",
      "-----------\n",
      "42\n",
      "0.2857142857142857 0.9285714285714286 0.7857142857142857\n",
      "0.6666666666666666\n",
      "-----------\n",
      "43\n",
      "0.2857142857142857 0.9285714285714286 0.7142857142857143\n",
      "0.6428571428571429\n",
      "-----------\n",
      "44\n",
      "0.2857142857142857 0.9285714285714286 0.7142857142857143\n",
      "0.6428571428571429\n",
      "-----------\n",
      "45\n",
      "0.2857142857142857 0.9285714285714286 0.7142857142857143\n",
      "0.6428571428571429\n",
      "-----------\n",
      "46\n",
      "0.2857142857142857 0.9285714285714286 0.7142857142857143\n",
      "0.6428571428571429\n",
      "-----------\n",
      "47\n",
      "0.2857142857142857 0.9285714285714286 0.7142857142857143\n",
      "0.6428571428571429\n",
      "-----------\n",
      "48\n",
      "0.2857142857142857 0.9285714285714286 0.6428571428571429\n",
      "0.6190476190476191\n",
      "-----------\n",
      "49\n",
      "0.2857142857142857 0.9285714285714286 0.6428571428571429\n",
      "0.6190476190476191\n",
      "-----------\n",
      "50\n",
      "0.2857142857142857 0.9285714285714286 0.6428571428571429\n",
      "0.6190476190476191\n",
      "-----------\n",
      "51\n",
      "0.2857142857142857 0.9285714285714286 0.5714285714285714\n",
      "0.5952380952380952\n",
      "-----------\n",
      "52\n",
      "0.2857142857142857 0.9285714285714286 0.5714285714285714\n",
      "0.5952380952380952\n",
      "-----------\n",
      "53\n",
      "0.2857142857142857 0.9285714285714286 0.5714285714285714\n",
      "0.5952380952380952\n",
      "-----------\n",
      "54\n",
      "0.35714285714285715 0.9285714285714286 0.5714285714285714\n",
      "0.6190476190476191\n",
      "-----------\n",
      "55\n",
      "0.35714285714285715 0.9285714285714286 0.5714285714285714\n",
      "0.6190476190476191\n",
      "-----------\n",
      "56\n",
      "0.35714285714285715 0.9285714285714286 0.5714285714285714\n",
      "0.6190476190476191\n",
      "-----------\n",
      "57\n",
      "0.35714285714285715 0.9285714285714286 0.5714285714285714\n",
      "0.6190476190476191\n",
      "-----------\n",
      "58\n",
      "0.35714285714285715 0.9285714285714286 0.5714285714285714\n",
      "0.6190476190476191\n",
      "-----------\n",
      "59\n",
      "0.35714285714285715 0.9285714285714286 0.5714285714285714\n",
      "0.6190476190476191\n",
      "-----------\n",
      "60\n",
      "0.35714285714285715 0.9285714285714286 0.5714285714285714\n",
      "0.6190476190476191\n",
      "-----------\n",
      "61\n",
      "0.35714285714285715 0.9285714285714286 0.5714285714285714\n",
      "0.6190476190476191\n",
      "-----------\n",
      "62\n",
      "0.35714285714285715 0.8571428571428571 0.5714285714285714\n",
      "0.5952380952380952\n",
      "-----------\n",
      "63\n",
      "0.35714285714285715 0.8571428571428571 0.5714285714285714\n",
      "0.5952380952380952\n",
      "-----------\n",
      "64\n",
      "0.35714285714285715 0.8571428571428571 0.5714285714285714\n",
      "0.5952380952380952\n",
      "-----------\n",
      "65\n",
      "0.35714285714285715 0.8571428571428571 0.5714285714285714\n",
      "0.5952380952380952\n",
      "-----------\n",
      "66\n",
      "0.35714285714285715 0.8571428571428571 0.5714285714285714\n",
      "0.5952380952380952\n",
      "-----------\n",
      "67\n",
      "0.35714285714285715 0.8571428571428571 0.5714285714285714\n",
      "0.5952380952380952\n",
      "-----------\n",
      "68\n",
      "0.35714285714285715 0.8571428571428571 0.5714285714285714\n",
      "0.5952380952380952\n",
      "-----------\n",
      "69\n",
      "0.42857142857142855 0.8571428571428571 0.5714285714285714\n",
      "0.619047619047619\n",
      "-----------\n",
      "70\n",
      "0.42857142857142855 0.8571428571428571 0.5714285714285714\n",
      "0.619047619047619\n",
      "-----------\n",
      "71\n",
      "0.42857142857142855 0.8571428571428571 0.5714285714285714\n",
      "0.619047619047619\n",
      "-----------\n",
      "72\n",
      "0.42857142857142855 0.8571428571428571 0.5714285714285714\n",
      "0.619047619047619\n",
      "-----------\n",
      "73\n",
      "0.42857142857142855 0.8571428571428571 0.5714285714285714\n",
      "0.619047619047619\n",
      "-----------\n",
      "74\n",
      "0.5 0.8571428571428571 0.5714285714285714\n",
      "0.6428571428571429\n",
      "-----------\n",
      "75\n",
      "0.5 0.8571428571428571 0.5714285714285714\n",
      "0.6428571428571429\n",
      "-----------\n",
      "76\n",
      "0.5 0.8571428571428571 0.5714285714285714\n",
      "0.6428571428571429\n",
      "-----------\n",
      "77\n",
      "0.5 0.8571428571428571 0.5714285714285714\n",
      "0.6428571428571429\n",
      "-----------\n",
      "78\n",
      "0.5 0.8571428571428571 0.5714285714285714\n",
      "0.6428571428571429\n",
      "-----------\n",
      "79\n",
      "0.5 0.8571428571428571 0.5714285714285714\n",
      "0.6428571428571429\n",
      "-----------\n",
      "80\n",
      "0.5 0.8571428571428571 0.5714285714285714\n",
      "0.6428571428571429\n",
      "-----------\n",
      "81\n",
      "0.5 0.8571428571428571 0.5714285714285714\n",
      "0.6428571428571429\n",
      "-----------\n",
      "82\n",
      "0.5 0.8571428571428571 0.5714285714285714\n",
      "0.6428571428571429\n",
      "-----------\n",
      "83\n",
      "0.5 0.8571428571428571 0.5714285714285714\n",
      "0.6428571428571429\n",
      "-----------\n",
      "84\n",
      "0.5 0.8571428571428571 0.5714285714285714\n",
      "0.6428571428571429\n",
      "-----------\n",
      "85\n",
      "0.5 0.7857142857142857 0.5714285714285714\n",
      "0.619047619047619\n",
      "-----------\n",
      "86\n",
      "0.5 0.7857142857142857 0.5714285714285714\n",
      "0.619047619047619\n",
      "-----------\n",
      "87\n",
      "0.5714285714285714 0.7857142857142857 0.5714285714285714\n",
      "0.6428571428571429\n",
      "-----------\n",
      "88\n",
      "0.5714285714285714 0.7857142857142857 0.5714285714285714\n",
      "0.6428571428571429\n",
      "-----------\n",
      "89\n",
      "0.5714285714285714 0.7142857142857143 0.5714285714285714\n",
      "0.619047619047619\n",
      "-----------\n",
      "90\n",
      "0.5714285714285714 0.7142857142857143 0.5714285714285714\n",
      "0.619047619047619\n",
      "-----------\n",
      "91\n",
      "0.5714285714285714 0.7142857142857143 0.5714285714285714\n",
      "0.619047619047619\n",
      "-----------\n",
      "92\n",
      "0.5714285714285714 0.7142857142857143 0.5714285714285714\n",
      "0.619047619047619\n",
      "-----------\n",
      "93\n",
      "0.6428571428571429 0.7142857142857143 0.5\n",
      "0.6190476190476191\n",
      "-----------\n",
      "94\n",
      "0.6428571428571429 0.7142857142857143 0.5\n",
      "0.6190476190476191\n",
      "-----------\n",
      "95\n",
      "0.6428571428571429 0.7142857142857143 0.5\n",
      "0.6190476190476191\n",
      "-----------\n",
      "96\n",
      "0.6428571428571429 0.7142857142857143 0.5\n",
      "0.6190476190476191\n",
      "-----------\n",
      "97\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "98\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "99\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "100\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "101\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "102\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "103\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "104\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "105\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "106\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "107\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "108\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "109\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "110\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "111\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "112\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "113\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "114\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "115\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "116\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "117\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "118\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "119\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "120\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "121\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "122\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "123\n",
      "0.6428571428571429 0.5714285714285714 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "124\n",
      "0.6428571428571429 0.5 0.5\n",
      "0.5476190476190476\n",
      "-----------\n",
      "125\n",
      "0.6428571428571429 0.5 0.5\n",
      "0.5476190476190476\n",
      "-----------\n",
      "126\n",
      "0.6428571428571429 0.5 0.5\n",
      "0.5476190476190476\n",
      "-----------\n",
      "127\n",
      "0.6428571428571429 0.5 0.5\n",
      "0.5476190476190476\n",
      "-----------\n",
      "128\n",
      "0.6428571428571429 0.5 0.5\n",
      "0.5476190476190476\n",
      "-----------\n",
      "129\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "130\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "131\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "132\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "133\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "134\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "135\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "136\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "137\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "138\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "139\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "140\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "141\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "142\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "143\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "144\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "145\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "146\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "147\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "148\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "149\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "150\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "151\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "152\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "153\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "154\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "155\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "156\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "157\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "158\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "159\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "160\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "161\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "162\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "163\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "164\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "165\n",
      "0.7142857142857143 0.5 0.5\n",
      "0.5714285714285715\n",
      "-----------\n",
      "166\n",
      "0.7142857142857143 0.5 0.42857142857142855\n",
      "0.5476190476190477\n",
      "-----------\n",
      "167\n",
      "0.7142857142857143 0.5 0.42857142857142855\n",
      "0.5476190476190477\n",
      "-----------\n",
      "168\n",
      "0.7142857142857143 0.5 0.42857142857142855\n",
      "0.5476190476190477\n",
      "-----------\n",
      "169\n",
      "0.7142857142857143 0.5 0.42857142857142855\n",
      "0.5476190476190477\n",
      "-----------\n",
      "170\n",
      "0.7142857142857143 0.5 0.42857142857142855\n",
      "0.5476190476190477\n",
      "-----------\n",
      "171\n",
      "0.7142857142857143 0.5 0.42857142857142855\n",
      "0.5476190476190477\n",
      "-----------\n",
      "172\n",
      "0.7857142857142857 0.5 0.42857142857142855\n",
      "0.5714285714285714\n",
      "-----------\n",
      "173\n",
      "0.8571428571428571 0.5 0.42857142857142855\n",
      "0.5952380952380952\n",
      "-----------\n",
      "174\n",
      "0.8571428571428571 0.5 0.42857142857142855\n",
      "0.5952380952380952\n",
      "-----------\n",
      "175\n",
      "0.8571428571428571 0.5 0.42857142857142855\n",
      "0.5952380952380952\n",
      "-----------\n",
      "176\n",
      "0.8571428571428571 0.5 0.42857142857142855\n",
      "0.5952380952380952\n",
      "-----------\n",
      "177\n",
      "0.8571428571428571 0.5 0.42857142857142855\n",
      "0.5952380952380952\n",
      "-----------\n",
      "178\n",
      "0.8571428571428571 0.5 0.42857142857142855\n",
      "0.5952380952380952\n",
      "-----------\n",
      "179\n",
      "0.8571428571428571 0.5 0.35714285714285715\n",
      "0.5714285714285715\n",
      "-----------\n",
      "180\n",
      "0.8571428571428571 0.42857142857142855 0.35714285714285715\n",
      "0.5476190476190476\n",
      "-----------\n",
      "181\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "182\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "183\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "184\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "185\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "186\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "187\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "188\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "189\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "190\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "191\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "192\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "193\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "194\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "195\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "196\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "197\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "198\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n",
      "-----------\n",
      "199\n",
      "0.8571428571428571 0.35714285714285715 0.35714285714285715\n",
      "0.5238095238095238\n"
     ]
    }
   ],
   "source": [
    "X_train\n",
    "y_train\n",
    "\n",
    "\n",
    "# 0 - NOT CHANGED\n",
    "# 1 - OFF ON\n",
    "# 2 - ON OFF\n",
    "\n",
    "def pred(image_1_full, number):\n",
    "    image_gray_1 = image_1_full[0:20, 0:20]\n",
    "    image_gray_2 = image_1_full[0:20, 20:40]\n",
    "    m = nn.AvgPool2d((5, 5))\n",
    "    output = m(torch.tensor([image_gray_1], dtype=torch.float64))\n",
    "    output2 = m(torch.tensor([image_gray_2], dtype=torch.float64))\n",
    "    sum1 = output.numpy()[0]-output2.numpy()[0]\n",
    "    sum2 =  output2.numpy()[0] - output.numpy()[0]\n",
    "    if sum1.sum() > number:\n",
    "        return 2\n",
    "    if sum1.sum() < -number:\n",
    "        return 1\n",
    "    if sum1.sum() < number and sum1.sum() > -number:\n",
    "        return 0\n",
    "\n",
    "\n",
    "number= 0\n",
    "while number !=200:\n",
    "  counter = [0,0,0]\n",
    "  for i in range(len(X_train)):\n",
    "      if pred(X_train[i], number) == y_train[i]:\n",
    "          counter[y_train[i]] +=1\n",
    "  print('-----------')\n",
    "  print(number)\n",
    "  print(counter[0]/14, counter[1]/14, counter[2]/14)\n",
    "  print((counter[0]/14 + counter[1]/14 + counter[2]/14)/3)\n",
    "  \n",
    "  \n",
    "  number += 1  \n",
    "        \n",
    "\n",
    "\n",
    "#80 - 0.6428571428571429\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "d551fa67-aae7-4534-ada2-d35561f3279c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.avgPool = nn.AvgPool2d((5, 5))\n",
    "        self.conv1 = nn.Conv2d(1, 5, 4)\n",
    "        self.fc = nn.Linear(25, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        print(x.shape)\n",
    "        x = self.avgPool(x)\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        print(x.shape)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "39381a12-1431-4ed4-974f-315c8149bfec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 20, 40])\n",
      "torch.Size([1, 1, 4, 8])\n",
      "torch.Size([1, 5, 1, 5])\n",
      "<bound method Module.parameters of Net2(\n",
      "  (avgPool): AvgPool2d(kernel_size=(5, 5), stride=(5, 5), padding=0)\n",
      "  (conv1): Conv2d(1, 5, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc): Linear(in_features=25, out_features=1, bias=True)\n",
      ")>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[586], line 21\u001b[0m\n\u001b[1;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# # in your training loop:\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# optimizer.zero_grad()   # zero the gradient buffers\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# output = net(torch.tensor([[image_1_full]],  dtype=torch.float) )\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# loss = criterion(output, torch.tensor([1]))\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# optimizer.step() \u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# make it the same shape as output\u001b[39;00m\n\u001b[1;32m     22\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "image_1_full = cv2.imread('/home/madmax/Documents/SK_articles/test_povorotniks/DATASET_FINAL_ONLY_TURN_LIGHTS/PAIRS_CLASSES/NOT_CHANGE/2_5.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "net = Net2()\n",
    "out = net(torch.tensor([[image_1_full]],  dtype=torch.float) )\n",
    "print(net.parameters)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# # in your training loop:\n",
    "# optimizer.zero_grad()   # zero the gradient buffers\n",
    "# output = net(torch.tensor([[image_1_full]],  dtype=torch.float) )\n",
    "# loss = criterion(output, torch.tensor([1]))\n",
    "# loss.backward()\n",
    "# optimizer.step() \n",
    "\n",
    "\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "08ef3e9d-bc42-4720-b3d5-1aa01c3f7eea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "tensor([[ 0.0034, -0.0201, -0.0312, -0.0868, -0.0073,  0.0880,  0.0171, -0.1192,\n",
      "         -0.0762,  0.0609]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def03800-1251-4e73-9355-73d35cfb2668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
